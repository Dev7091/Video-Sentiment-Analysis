# Video Sentiment Analysis

## Description
The Video Sentiment Analysis project is designed to detect faces in videos and analyze their expressions. It creates bounding boxes around detected faces and labels them with the corresponding sentiment, such as Happy, Sad, Angry, etc. Additionally, this project can handle text sentiment analysis (like subtitles in a video) and audio sentiment analysis. This project is built using Flask, making it accessible as a web application for various use cases.

## Features
- Detects faces in video frames and identifies facial expressions.
- Draws bounding boxes around detected faces with expression labels.
- Performs text sentiment analysis on subtitles within the video.
- Conducts audio sentiment analysis on the video audio track.
- Real-time sentiment analysis of video content.

## Dependencies
- Flask
- OpenCV
- TensorFlow/Keras
- dlib
- numpy
- matplotlib
- textblob (for text sentiment analysis)
- librosa (for audio sentiment analysis)

## Contributions
This repository is created by [Tatwadarshi](https://github.com/Dev7091).We welcome contributions to enhance the functionality and features of this project. Feel free to open issues or submit pull requests.

## License

This project is released under the [MIT License](LICENSE). You can find the specific terms and conditions outlined in the LICENSE file. This means you're free to utilize, modify, and distribute the project according to the terms of the MIT License.
